{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efa53c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Tue Oct 27 15:33:37 2020.\n",
    "\n",
    "@author: Charlotte Liotta\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f282abfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "CondaHTTPError: HTTP 000 CONNECTION FAILED for url <https://conda.anaconda.org/conda-forge/win-64/current_repodata.json>\n",
      "Elapsed: -\n",
      "\n",
      "An HTTP error occurred when trying to retrieve this URL.\n",
      "HTTP errors are often intermittent, and a simple retry will get you on your way.\n",
      "'https//conda.anaconda.org/conda-forge/win-64'\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install nbsphinx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ed3571",
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "Preamble"
   },
   "outputs": [],
   "source": [
    "\n",
    "# IMPORT PACKAGES\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "import inputs.data as inpdt\n",
    "import inputs.parameters_and_options as inpprm\n",
    "\n",
    "import equilibrium.compute_equilibrium as eqcmp\n",
    "import equilibrium.run_simulations as eqsim\n",
    "import equilibrium.functions_dynamic as eqdyn\n",
    "\n",
    "import calibration.calib_main_func as calmain\n",
    "\n",
    "print(\"Import packages and define file paths\")\n",
    "\n",
    "\n",
    "# DEFINE FILE PATHS\n",
    "\n",
    "path_code = '..'\n",
    "path_folder = path_code + '/2. Data/'\n",
    "path_precalc_inp = path_folder + '0. Precalculated inputs/'\n",
    "path_data = path_folder + 'data_Cape_Town/'\n",
    "path_precalc_transp = path_folder + 'precalculated_transport/'\n",
    "path_scenarios = path_folder + 'data_Cape_Town/Scenarios/'\n",
    "path_outputs = path_code + '/4. Sorties/'\n",
    "path_floods = path_folder + \"FATHOM/\"\n",
    "\n",
    "# TODO: rethink folder architecture\n",
    "\n",
    "\n",
    "# START TIMER FOR CODE OPTIMIZATION\n",
    "\n",
    "start = time.process_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1a8f0c",
   "metadata": {
    "title": "Import parameters and options"
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"Import default parameters and options, define custom ones\")\n",
    "\n",
    "# TODO: convert excel to csv\n",
    "\n",
    "# IMPORT PARAMETERS AND OPTIONS\n",
    "\n",
    "options = inpprm.import_options()\n",
    "param = inpprm.import_param(\n",
    "    path_precalc_inp, path_outputs, path_folder, options)\n",
    "\n",
    "# Set custom options for this simulation\n",
    "#  Dummy for taking floods into account in the utility function\n",
    "options[\"agents_anticipate_floods\"] = 1\n",
    "#  Dummy for preventing new informal settlement development\n",
    "options[\"informal_land_constrained\"] = 0\n",
    "#  TODO: add option to take into account less likely developments?\n",
    "\n",
    "\n",
    "# More custom options regarding flood model\n",
    "#  Dummy for taking pluvial floods into account (on top of fluvial floods)\n",
    "options[\"pluvial\"] = 1\n",
    "#  Dummy for reducing pluvial risk for (better protected) formal structures\n",
    "options[\"correct_pluvial\"] = 1\n",
    "#  Dummy for taking coastal floods into account (on top of fluvial floods)\n",
    "options[\"coastal\"] = 1\n",
    "#  Digital elevation to be used with coastal flood data (MERITDEM or NASADEM)\n",
    "#  NB: MERITDEM is also the DEM used for fluvial and pluvial flood data\n",
    "options[\"dem\"] = \"MERITDEM\"\n",
    "#  We consider undefended flood maps as our default because they are more\n",
    "#  reliable??\n",
    "#  TODO: algorithm converges better with defended maps??\n",
    "options[\"defended\"] = 1\n",
    "#  Dummy for taking sea-level rise into account in coastal flood data\n",
    "#  NB: Projections are up to 2050, based upon IPCC AR5 assessment for the\n",
    "#  RCP 8.5 scenario\n",
    "options[\"slr\"] = 1\n",
    "\n",
    "# More custom options regarding scenarios\n",
    "options[\"inc_ineq_scenario\"] = 2\n",
    "options[\"pop_growth_scenario\"] = 3\n",
    "options[\"fuel_price_scenario\"] = 2\n",
    "\n",
    "# Re-processing options: default is set at zero to save computing time (data\n",
    "# is simply loaded in the model)\n",
    "# NB: this is only needed to create the data for the first time, or when the\n",
    "# source is changed, so that pre-processed data is updated\n",
    "options[\"convert_sal_data\"] = 0\n",
    "options[\"compute_net_income\"] = 0\n",
    "\n",
    "# RE-RUN CALIBRATION: note that this takes time and is only useful for the\n",
    "# first time or if data used for calibration changes\n",
    "options[\"run_calib\"] = 0\n",
    "\n",
    "#  SET TIMELINE FOR SIMULATIONS\n",
    "t = np.arange(0, 30)\n",
    "\n",
    "# GIVE NAME TO SIMULATION TO EXPORT THE RESULTS\n",
    "# (change according to custom parameters to be included)\n",
    "\n",
    "name = ('floods' + str(options[\"agents_anticipate_floods\"])\n",
    "        + str(options[\"informal_land_constrained\"])\n",
    "        + '_F' + str(options[\"defended\"])\n",
    "        + '_P' + str(options[\"pluvial\"]) + str(options[\"correct_pluvial\"])\n",
    "        + '_C' + str(options[\"coastal\"]) + str(options[\"slr\"])\n",
    "        + '_scenario' + str(options[\"inc_ineq_scenario\"])\n",
    "        + str(options[\"pop_growth_scenario\"])\n",
    "        + str(options[\"fuel_price_scenario\"]))\n",
    "\n",
    "path_plots = path_outputs + name + '/plots/'\n",
    "\n",
    "# TODO: need to talk about numeric parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae00261",
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "Load data"
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"Load and pre-process data to be used in model (may take some time\"\n",
    "      + \" when agents anticipate floods and we re-process some data)\")\n",
    "\n",
    "\n",
    "# BASIC GEOGRAPHIC DATA\n",
    "\n",
    "grid, center = inpdt.import_grid(path_data)\n",
    "amenities = inpdt.import_amenities(path_precalc_inp, options)\n",
    "\n",
    "\n",
    "# MACRO DATA\n",
    "\n",
    "(interest_rate, population, housing_type_data, total_RDP\n",
    " ) = inpdt.import_macro_data(param, path_scenarios, path_folder)\n",
    "\n",
    "\n",
    "# HOUSEHOLDS AND INCOME DATA\n",
    "\n",
    "income_class_by_housing_type = inpdt.import_hypothesis_housing_type()\n",
    "\n",
    "#  See appendix A1 for income group and housing type definitions\n",
    "(mean_income, households_per_income_class, average_income, income_mult,\n",
    " income_2011, households_per_income_and_housing\n",
    " ) = inpdt.import_income_classes_data(param, path_data)\n",
    "\n",
    "#  We create this parameter to maintain money illusion in simulations\n",
    "#  (see eqsim.run_simulation)\n",
    "#  NB: set as a variable, not a parameter?\n",
    "param[\"income_year_reference\"] = mean_income\n",
    "\n",
    "#  Other data at SP level used for calibration and validation\n",
    "(data_rdp, housing_types_sp, data_sp, mitchells_plain_grid_2011,\n",
    " grid_formal_density_HFA, threshold_income_distribution, income_distribution,\n",
    " cape_town_limits) = inpdt.import_households_data(path_precalc_inp)\n",
    "\n",
    "#  Import nb of households per pixel, by housing type (from SAL data).\n",
    "#  Note that RDP is included in formal, and there are both formal and informal\n",
    "#  backyards\n",
    "\n",
    "if options[\"convert_sal_data\"] == 1:\n",
    "    print(\"Convert SAL data to grid dimensions - start\")\n",
    "    housing_types = inpdt.import_sal_data(grid, path_folder, path_data,\n",
    "                                          housing_type_data)\n",
    "    print(\"Convert SAL data to grid dimensions - end\")\n",
    "\n",
    "housing_types = pd.read_excel(path_folder + 'housing_types_grid_sal.xlsx')\n",
    "housing_types[np.isnan(housing_types)] = 0\n",
    "\n",
    "# LAND USE PROJECTIONS\n",
    "\n",
    "(spline_RDP, spline_estimate_RDP, spline_land_RDP,\n",
    " spline_land_backyard, spline_land_informal, spline_land_constraints,\n",
    " number_properties_RDP) = (\n",
    "     inpdt.import_land_use(grid, options, param, data_rdp, housing_types,\n",
    "                           housing_type_data, path_data, path_folder)\n",
    "     )\n",
    "\n",
    "#  We correct areas for each housing type at baseline year for the amount of\n",
    "#  constructible land in each type\n",
    "coeff_land = inpdt.import_coeff_land(\n",
    "    spline_land_constraints, spline_land_backyard, spline_land_informal,\n",
    "    spline_land_RDP, param, 0)\n",
    "\n",
    "#  We update land use parameters at baseline (relies on loaded data)\n",
    "housing_limit = inpdt.import_housing_limit(grid, param)\n",
    "\n",
    "#  NB: plug outputs in a new variable (not param) and adapt linked functions?\n",
    "(param, minimum_housing_supply, agricultural_rent\n",
    " ) = inpprm.import_construction_parameters(\n",
    "    param, grid, housing_types_sp, data_sp[\"dwelling_size\"],\n",
    "    mitchells_plain_grid_2011, grid_formal_density_HFA, coeff_land,\n",
    "    interest_rate, options\n",
    "    )\n",
    "\n",
    "# FLOOD DATA (takes some time when agents anticipate floods)\n",
    "#  NB: create a new variable instead of storing in param\n",
    "#  NB: WBUS2 corresponds to old data from CoCT (not useful anymore with FATHOM)\n",
    "#  param = inpdt.infer_WBUS2_depth(housing_types, param, path_floods)\n",
    "if options[\"agents_anticipate_floods\"] == 1:\n",
    "    print(\"Compute flood damages for each damage category - start\")\n",
    "    (fraction_capital_destroyed, structural_damages_small_houses,\n",
    "     structural_damages_medium_houses, structural_damages_large_houses,\n",
    "     content_damages, structural_damages_type1, structural_damages_type2,\n",
    "     structural_damages_type3a, structural_damages_type3b,\n",
    "     structural_damages_type4a, structural_damages_type4b\n",
    "     ) = inpdt.import_full_floods_data(options, param, path_folder,\n",
    "                                       housing_type_data)\n",
    "    print(\"Compute flood damages for each damage category - end\")\n",
    "\n",
    "elif options[\"agents_anticipate_floods\"] == 0:\n",
    "    fraction_capital_destroyed = pd.DataFrame()\n",
    "    fraction_capital_destroyed[\"structure_formal_2\"] = np.zeros(24014)\n",
    "    fraction_capital_destroyed[\"structure_formal_1\"] = np.zeros(24014)\n",
    "    fraction_capital_destroyed[\"structure_subsidized_2\"] = np.zeros(24014)\n",
    "    fraction_capital_destroyed[\"structure_subsidized_1\"] = np.zeros(24014)\n",
    "    fraction_capital_destroyed[\"contents_formal\"] = np.zeros(24014)\n",
    "    fraction_capital_destroyed[\"contents_informal\"] = np.zeros(24014)\n",
    "    fraction_capital_destroyed[\"contents_subsidized\"] = np.zeros(24014)\n",
    "    fraction_capital_destroyed[\"contents_backyard\"] = np.zeros(24014)\n",
    "    fraction_capital_destroyed[\"structure_backyards\"] = np.zeros(24014)\n",
    "    fraction_capital_destroyed[\"structure_formal_backyards\"] = np.zeros(24014)\n",
    "    fraction_capital_destroyed[\"structure_informal_backyards\"\n",
    "                               ] = np.zeros(24014)\n",
    "    fraction_capital_destroyed[\"structure_informal_settlements\"\n",
    "                               ] = np.zeros(24014)\n",
    "\n",
    "\n",
    "# SCENARIOS\n",
    "\n",
    "(spline_agricultural_rent, spline_interest_rate,\n",
    " spline_population_income_distribution, spline_inflation,\n",
    " spline_income_distribution, spline_population,\n",
    " spline_income, spline_minimum_housing_supply, spline_fuel\n",
    " ) = eqdyn.import_scenarios(income_2011, param, grid, path_scenarios,\n",
    "                            options)\n",
    "\n",
    "#  Import income net of commuting costs, as calibrated in Pfeiffer et al.\n",
    "#  (see part 3.1 or appendix C3)\n",
    "\n",
    "if options[\"compute_net_income\"] == 1:\n",
    "    print(\"Compute local incomes net of commuting costs for every simulation\"\n",
    "          + \" period - start\")\n",
    "    for t_temp in t:\n",
    "        print(t_temp)\n",
    "        (incomeNetOfCommuting, modalShares, ODflows, averageIncome\n",
    "         ) = inpdt.import_transport_data(\n",
    "             grid, param, t_temp, households_per_income_class, average_income,\n",
    "             spline_inflation, spline_fuel,\n",
    "             spline_population_income_distribution, spline_income_distribution,\n",
    "             path_precalc_inp, path_precalc_transp, 'GRID', options)\n",
    "        print(\"Compute local incomes net of commuting costs for every\"\n",
    "              + \" simulation period - end\")\n",
    "\n",
    "income_net_of_commuting_costs = np.load(\n",
    "    path_precalc_transp + 'GRID_incomeNetOfCommuting_0.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6755bde",
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "Re-run calibration (takes time, only if needed)"
   },
   "outputs": [],
   "source": [
    "\n",
    "# NB: use np.linspace instead of np.arange?\n",
    "\n",
    "if options[\"run_calib\"] == 1:\n",
    "\n",
    "    print(\"Calibration process - start\")\n",
    "\n",
    "    # PREAMBLE\n",
    "\n",
    "    if options[\"correct_dominant_incgrp\"] == 0:\n",
    "        # We associate income group to each census block according to median\n",
    "        # income\n",
    "        data_income_group = np.zeros(len(data_sp[\"income\"]))\n",
    "        for j in range(0, param[\"nb_of_income_classes\"] - 1):\n",
    "            data_income_group[data_sp[\"income\"] >\n",
    "                              threshold_income_distribution[j]] = j+1\n",
    "    elif options[\"correct_dominant_incgrp\"] == 1:\n",
    "        # We use more numerous group instead\n",
    "        data_income_group = np.zeros(len(income_distribution))\n",
    "        for i in range(0, len(income_distribution)):\n",
    "            data_income_group[i] = np.argmax(income_distribution[i])\n",
    "    # Although the second option seems more logical, it may make sense to use\n",
    "    # the first one given that we are going to regress on median SP prices\n",
    "\n",
    "    # We get the number of formal housing units per SP\n",
    "    # NB: it is not clear whether RDP are included in SP formal count, and\n",
    "    # if they should be taken out based on imperfect cadastral estimations.\n",
    "    # For our benchmark, we prefer to rely on sample selection.\n",
    "\n",
    "    if options[\"substract_RDP_from_formal\"] == 1:\n",
    "        # We retrieve number of RDP units per SP from grid-level data\n",
    "        grid_intersect = pd.read_csv(path_data + 'grid_SP_intersect.csv',\n",
    "                                     sep=';')\n",
    "        # When pixels are associated to several SPs, we allocate them to the\n",
    "        # one with the biggest intersection area.\n",
    "        # NB: it would be more rigorous to split the number of RDP across\n",
    "        # SPs according to their respective intersection areas, but this is\n",
    "        # unlikely to change much\n",
    "        grid_intersect = grid_intersect.groupby('ID_grille').max('Area')\n",
    "        data_rdp[\"ID_grille\"] = data_rdp.index\n",
    "        data_rdp[\"ID_grille\"] = data_rdp[\"ID_grille\"] + 1\n",
    "\n",
    "        rdp_grid = pd.merge(data_rdp, grid_intersect, on=\"ID_grille\",\n",
    "                            how=\"outer\")\n",
    "        rdp_sp = rdp_grid.groupby('SP_CODE')['count'].sum()\n",
    "        rdp_sp = rdp_sp.reset_index()\n",
    "        rdp_sp = rdp_sp.rename(columns={'SP_CODE': 'sp_code'})\n",
    "        # We just fill the list with unmatched SPs to get the full SP vector\n",
    "        rdp_sp_fill = pd.merge(rdp_sp, data_sp['sp_code'], on=\"sp_code\",\n",
    "                               how=\"outer\")\n",
    "        rdp_sp_fill['count'] = rdp_sp_fill['count'].fillna(0)\n",
    "        rdp_sp_fill = rdp_sp_fill.sort_values(by='sp_code')\n",
    "\n",
    "        data_number_formal = (\n",
    "            housing_types_sp.total_dwellings_SP_2011\n",
    "            - housing_types_sp.backyard_SP_2011\n",
    "            - housing_types_sp.informal_SP_2011\n",
    "            - rdp_sp_fill['count'])\n",
    "\n",
    "    elif options[\"substract_RDP_from_formal\"] == 0:\n",
    "        data_number_formal = (\n",
    "            housing_types_sp.total_dwellings_SP_2011\n",
    "            - housing_types_sp.backyard_SP_2011\n",
    "            - housing_types_sp.informal_SP_2011\n",
    "            )\n",
    "\n",
    "    # Although it makes more sense to substract RDP from number of formal\n",
    "    # private units, it may make sense to keep them if we are unable to select\n",
    "    # SPs with few RDP units\n",
    "\n",
    "    # Note that SP housing type data contain more households than SAL housing\n",
    "    # type data, or aggregate income data (with fewer backyards and more of\n",
    "    # everything else): in fact, it seems to include more SPs\n",
    "\n",
    "    # We select the data points we are going to use (cf. appendix C2).\n",
    "    # As Cobb-Douglas log-linear relation is only true for the formal sector,\n",
    "    # we exclude SPs in the bottom quintile of property prices and for which\n",
    "    # more than 5% of households are reported to live in \"informal\" housing.\n",
    "    # We also exclude \"rural\" SPs (i.e., those that are large, with a small\n",
    "    # share than can be urbanized).\n",
    "\n",
    "    # NB: we also add other criteria compared to the working paper, namely we\n",
    "    # exclude poorest income group (which is in effect crowded out from the\n",
    "    # formal sector), as well as Mitchell's Plain (as its housing market is\n",
    "    # very specific) and far-away land (for which we have few observations)\n",
    "\n",
    "    if options[\"correct_selected_density\"] == 0:\n",
    "        selected_density = (\n",
    "            (data_sp[\"price\"] > np.nanquantile(data_sp[\"price\"], 0.2))\n",
    "            & (data_number_formal\n",
    "               > 0.95 * housing_types_sp.total_dwellings_SP_2011)\n",
    "            & (data_sp[\"unconstrained_area\"]\n",
    "                < np.nanquantile(data_sp[\"unconstrained_area\"], 0.8))\n",
    "            & (data_sp[\"unconstrained_area\"] > 0.6 * 1000000 * data_sp[\"area\"])\n",
    "            )\n",
    "    elif (options[\"correct_selected_density\"] == 1\n",
    "          and options[\"correct_mitchells_plain\"] == 0):\n",
    "        selected_density = (\n",
    "            (data_sp[\"price\"] > np.nanquantile(data_sp[\"price\"], 0.2))\n",
    "            & (data_number_formal\n",
    "               > 0.95 * housing_types_sp.total_dwellings_SP_2011)\n",
    "            & (data_sp[\"unconstrained_area\"]\n",
    "                < np.nanquantile(data_sp[\"unconstrained_area\"], 0.8))\n",
    "            & (data_sp[\"unconstrained_area\"] > 0.6 * 1000000 * data_sp[\"area\"])\n",
    "            & (data_income_group > 0)\n",
    "            & (data_sp[\"distance\"] < 40)\n",
    "            )\n",
    "    elif (options[\"correct_selected_density\"] == 1\n",
    "          and options[\"correct_mitchells_plain\"] == 1):\n",
    "        selected_density = (\n",
    "            (data_sp[\"price\"] > np.nanquantile(data_sp[\"price\"], 0.2))\n",
    "            & (data_number_formal\n",
    "               > 0.95 * housing_types_sp.total_dwellings_SP_2011)\n",
    "            & (data_sp[\"unconstrained_area\"]\n",
    "                < np.nanquantile(data_sp[\"unconstrained_area\"], 0.8))\n",
    "            & (data_sp[\"unconstrained_area\"] > 0.6 * 1000000 * data_sp[\"area\"])\n",
    "            & (data_income_group > 0)\n",
    "            & (data_sp[\"mitchells_plain\"] == 0)\n",
    "            & (data_sp[\"distance\"] < 40)\n",
    "            )\n",
    "\n",
    "    # NB: re-run the following regressions with robust standard errors\n",
    "\n",
    "    # CONSTRUCTION FUNCTION PARAMETERS\n",
    "\n",
    "    # We then estimate the coefficients of construction function\n",
    "    coeff_b, coeff_a, coeffKappa = calmain.estim_construct_func_param(\n",
    "        options, param, data_sp, threshold_income_distribution,\n",
    "        income_distribution, data_rdp, housing_types_sp,\n",
    "        data_number_formal, data_income_group, selected_density,\n",
    "        path_data, path_precalc_inp, path_folder)\n",
    "\n",
    "    # NB: relation between invested capital and building density to back up\n",
    "    # values of empirical estimates?\n",
    "\n",
    "    # We update parameter vector\n",
    "    param[\"coeff_a\"] = coeff_a\n",
    "    param[\"coeff_b\"] = coeff_b\n",
    "    param[\"coeff_A\"] = coeffKappa\n",
    "\n",
    "    # INCOMES AND GRAVITY PARAMETER\n",
    "\n",
    "    # We scan values for the gravity parameter to estimate incomes as a\n",
    "    # function of it.\n",
    "    # The value range is set by trial and error: the wider the range you want\n",
    "    # to test, the longer.\n",
    "    if options[\"scan_type\"] == \"rough\":\n",
    "        list_lambda = 10 ** np.arange(0.40, 0.51, 0.05)\n",
    "    if options[\"scan_type\"] == \"normal\":\n",
    "        list_lambda = 10 ** np.arange(0.42, 0.441, 0.01)\n",
    "    if options[\"scan_type\"] == \"fine\":\n",
    "        list_lambda = 10 ** np.arange(0.427, 0.4291, 0.001)\n",
    "\n",
    "    # NB: this is too long and complex to run a solver directly\n",
    "    # NB: We need to proceed in two steps as errors were drawn directly on\n",
    "    # transport costs (and not on commuting pairs), hence no separate\n",
    "    # identification of the gravity parameter and the incomes net of commuting\n",
    "    # costs\n",
    "\n",
    "    (incomeCentersKeep, lambdaKeep, cal_avg_income, scoreKeep,\n",
    "     bhattacharyyaDistances) = (\n",
    "        calmain.estim_incomes_and_gravity(\n",
    "            param, grid, list_lambda, households_per_income_class,\n",
    "            average_income, income_distribution, spline_inflation, spline_fuel,\n",
    "            spline_population_income_distribution, spline_income_distribution,\n",
    "            path_data, path_precalc_inp, path_precalc_transp, options)\n",
    "        )\n",
    "\n",
    "    # NB: compare estimates with existing literature\n",
    "\n",
    "    # We validate calibrated incomes\n",
    "    data_graph = pd.DataFrame(\n",
    "        {'Calibration': cal_avg_income,\n",
    "         'Data': average_income},\n",
    "        index=[\"Poor\", \"Mid-poor\", \"Mid-rich\", \"Rich\"])\n",
    "    figure, axis = plt.subplots(1, 1, figsize=(10, 7))\n",
    "    figure.tight_layout()\n",
    "    data_graph.plot(kind=\"bar\", ax=axis)\n",
    "    plt.ylabel(\"Average income\")\n",
    "    plt.tick_params(labelbottom=True)\n",
    "    plt.xticks(rotation='horizontal')\n",
    "    # plt.savefig(path_plots + 'validation_cal_income.png')\n",
    "    # plt.close()\n",
    "\n",
    "    # We update parameter vector\n",
    "    param[\"lambda\"] = np.array(lambdaKeep)\n",
    "\n",
    "    # UTILITY FUNCTION PARAMETERS\n",
    "\n",
    "    # We compute local incomes net of commuting costs at the SP (not grid)\n",
    "    # level that is used in calibration\n",
    "    # Note that lambda and calibrated incomes have an impact here:\n",
    "    # from now on, we will stop loading precalibrated parameters\n",
    "    options[\"load_precal_param\"] = 0\n",
    "    (incomeNetOfCommuting, *_\n",
    "     ) = inpdt.import_transport_data(\n",
    "         grid, param, 0, households_per_income_class, average_income,\n",
    "         spline_inflation, spline_fuel,\n",
    "         spline_population_income_distribution, spline_income_distribution,\n",
    "         path_precalc_inp, path_precalc_transp, 'SP', options)\n",
    "\n",
    "    # Note that we dropped potential spatial autocorrelation for numerical\n",
    "    # simplicity\n",
    "\n",
    "    # Here, we also have an impact from construction parameters and sample\n",
    "    # selection (+ number of formal units)\n",
    "\n",
    "    # TODO: q0 needs to be fixed for the solver to be stable!\n",
    "    (calibratedUtility_beta, calibratedUtility_q0, cal_amenities\n",
    "     ) = calmain.estim_util_func_param(\n",
    "         data_number_formal, data_income_group, housing_types_sp, data_sp,\n",
    "         coeff_a, coeff_b, coeffKappa, interest_rate,\n",
    "         incomeNetOfCommuting, selected_density, path_data, path_precalc_inp,\n",
    "         options, param)\n",
    "\n",
    "    # param[\"beta\"] = calibratedUtility_beta\n",
    "    # param[\"q0\"] = calibratedUtility_q0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ec1504",
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "Reload calibrated data"
   },
   "outputs": [],
   "source": [
    "\n",
    "if options[\"run_calib\"] == 1:\n",
    "\n",
    "    # First, incomes net of commuting costs for all periods\n",
    "    for t_temp in t:\n",
    "        print(t_temp)\n",
    "        (incomeNetOfCommuting, modalShares, ODflows, averageIncome\n",
    "         ) = inpdt.import_transport_data(\n",
    "             grid, param, t_temp, households_per_income_class, average_income,\n",
    "             spline_inflation, spline_fuel,\n",
    "             spline_population_income_distribution, spline_income_distribution,\n",
    "             path_precalc_inp, path_precalc_transp, 'GRID', options)\n",
    "\n",
    "    income_net_of_commuting_costs = np.load(\n",
    "        path_precalc_transp + 'GRID_incomeNetOfCommuting_0.npy')\n",
    "\n",
    "    # Then, amenity data\n",
    "    amenities = inpdt.import_amenities(path_precalc_inp, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2cb92d",
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "End calibration by fitting disamenity parameter for backyard"
   },
   "outputs": [],
   "source": [
    "# and informal housing to the model\n",
    "\n",
    "# Unemployment reweighting does not work fine: results should be shown for\n",
    "# employed population\n",
    "\n",
    "if options[\"run_calib\"] == 1:\n",
    "\n",
    "    # General calibration (see Pfeiffer et al., appendix C5)\n",
    "\n",
    "    list_amenity_backyard = np.arange(0.64, 0.681, 0.01)\n",
    "    list_amenity_settlement = np.arange(0.60, 0.641, 0.01)\n",
    "    housing_type_total = pd.DataFrame(np.array(np.meshgrid(\n",
    "        list_amenity_backyard, list_amenity_settlement)).T.reshape(-1, 2))\n",
    "    housing_type_total.columns = [\"param_backyard\", \"param_settlement\"]\n",
    "    housing_type_total[\"formal\"] = np.zeros(\n",
    "        len(housing_type_total.param_backyard))\n",
    "    housing_type_total[\"backyard\"] = np.zeros(\n",
    "        len(housing_type_total.param_backyard))\n",
    "    housing_type_total[\"informal\"] = np.zeros(\n",
    "        len(housing_type_total.param_backyard))\n",
    "    housing_type_total[\"subsidized\"] = np.zeros(\n",
    "        len(housing_type_total.param_backyard))\n",
    "\n",
    "    debut_calib_time = time.process_time()\n",
    "    number_total_iterations = (\n",
    "        len(list_amenity_backyard) * len(list_amenity_settlement))\n",
    "    print(f\"** Calibration: {number_total_iterations} iterations **\")\n",
    "\n",
    "    for i in range(0, len(list_amenity_backyard)):\n",
    "        for j in range(0, len(list_amenity_settlement)):\n",
    "            param[\"amenity_backyard\"] = list_amenity_backyard[i]\n",
    "            param[\"amenity_settlement\"] = list_amenity_settlement[j]\n",
    "            param[\"pockets\"] = np.ones(24014) * param[\"amenity_settlement\"]\n",
    "            param[\"backyard_pockets\"] = (np.ones(24014)\n",
    "                                         * param[\"amenity_backyard\"])\n",
    "            (initial_state_utility,\n",
    "             initial_state_error,\n",
    "             initial_state_simulated_jobs,\n",
    "             initial_state_households_housing_types,\n",
    "             initial_state_household_centers,\n",
    "             initial_state_households,\n",
    "             initial_state_dwelling_size,\n",
    "             initial_state_housing_supply,\n",
    "             initial_state_rent,\n",
    "             initial_state_rent_matrix,\n",
    "             initial_state_capital_land,\n",
    "             initial_state_average_income,\n",
    "             initial_state_limit_city) = eqcmp.compute_equilibrium(\n",
    "                 fraction_capital_destroyed,\n",
    "                 amenities,\n",
    "                 param,\n",
    "                 housing_limit,\n",
    "                 population,\n",
    "                 households_per_income_class,\n",
    "                 total_RDP,\n",
    "                 coeff_land,\n",
    "                 income_net_of_commuting_costs,\n",
    "                 grid,\n",
    "                 options,\n",
    "                 agricultural_rent,\n",
    "                 interest_rate,\n",
    "                 number_properties_RDP,\n",
    "                 average_income,\n",
    "                 mean_income,\n",
    "                 income_class_by_housing_type,\n",
    "                 minimum_housing_supply,\n",
    "                 param[\"coeff_A\"],\n",
    "                 income_2011)\n",
    "\n",
    "            # We fill output matrix with the total number of HHs per housing\n",
    "            # type for given values of backyard and informal amenity parameters\n",
    "            housing_type_total.iloc[\n",
    "                (housing_type_total.param_backyard\n",
    "                 == param[\"amenity_backyard\"])\n",
    "                & (housing_type_total.param_settlement\n",
    "                   == param[\"amenity_settlement\"]),\n",
    "                2:6] = np.nansum(initial_state_households_housing_types, 1)\n",
    "            time_elapsed = time.process_time() - debut_calib_time\n",
    "            iteration_number = i * len(list_amenity_settlement) + j + 1\n",
    "\n",
    "            print(f\"iteration {iteration_number}/{number_total_iterations}.\",\n",
    "                  str(datetime.timedelta(seconds=round(time_elapsed))),\n",
    "                  f\"elapsed ({round(time_elapsed/iteration_number)}s per iter\",\n",
    "                  \"There remains:\",\n",
    "                  str(datetime.timedelta(seconds=round(\n",
    "                      time_elapsed\n",
    "                      / iteration_number\n",
    "                      * (number_total_iterations-iteration_number)))))\n",
    "\n",
    "    # We choose the set of parameters that minimize the sum of abs differences\n",
    "    # between simulated and observed total number of households in each housing\n",
    "    # type (without RDP, which is exogenously set equal to data)\n",
    "\n",
    "    distance_share = np.abs(\n",
    "        housing_type_total.iloc[:, 2:5] - housing_type_data[None, 0:3])\n",
    "    distance_share_score = (\n",
    "        distance_share.iloc[:, 1] + distance_share.iloc[:, 2])\n",
    "\n",
    "    which = np.argmin(distance_share_score)\n",
    "    min_score = np.nanmin(distance_share_score)\n",
    "    calibrated_amenities = housing_type_total.iloc[which, 0:2]\n",
    "\n",
    "    param[\"amenity_backyard\"] = calibrated_amenities[0]\n",
    "    param[\"amenity_settlement\"] = calibrated_amenities[1]\n",
    "\n",
    "    try:\n",
    "        os.mkdir(path_precalc_inp)\n",
    "    except OSError as error:\n",
    "        print(error)\n",
    "\n",
    "    # Works the same as in paper\n",
    "    np.save(path_precalc_inp + 'param_amenity_backyard.npy',\n",
    "            param[\"amenity_backyard\"])\n",
    "    np.save(path_precalc_inp + 'param_amenity_settlement.npy',\n",
    "            param[\"amenity_settlement\"])\n",
    "\n",
    "    if options[\"location_based_calib\"] == 1:\n",
    "\n",
    "        index = 0\n",
    "        index_max = 50\n",
    "        metrics = np.zeros(index_max)\n",
    "\n",
    "        # We start from where we left (to gain time) and compute the\n",
    "        # equilibrium again\n",
    "        param[\"pockets\"] = np.zeros(24014) + param[\"amenity_settlement\"]\n",
    "        save_param_informal_settlements = np.zeros((index_max, 24014))\n",
    "        metrics_is = np.zeros(index_max)\n",
    "        param[\"backyard_pockets\"] = np.zeros(24014) + param[\"amenity_backyard\"]\n",
    "        save_param_backyards = np.zeros((index_max, 24014))\n",
    "        metrics_ib = np.zeros(index_max)\n",
    "\n",
    "        print(\"\\n* City limits *\")\n",
    "\n",
    "        (initial_state_utility,\n",
    "         initial_state_error,\n",
    "         initial_state_simulated_jobs,\n",
    "         initial_state_households_housing_types,\n",
    "         initial_state_household_centers,\n",
    "         initial_state_households,\n",
    "         initial_state_dwelling_size,\n",
    "         initial_state_housing_supply,\n",
    "         initial_state_rent,\n",
    "         initial_state_rent_matrix,\n",
    "         initial_state_capital_land,\n",
    "         initial_state_average_income,\n",
    "         initial_state_limit_city\n",
    "         ) = eqcmp.compute_equilibrium(\n",
    "             fraction_capital_destroyed,\n",
    "             amenities,\n",
    "             param,\n",
    "             housing_limit,\n",
    "             population,\n",
    "             households_per_income_class,\n",
    "             total_RDP,\n",
    "             coeff_land,\n",
    "             income_net_of_commuting_costs,\n",
    "             grid,\n",
    "             options,\n",
    "             agricultural_rent,\n",
    "             interest_rate,\n",
    "             number_properties_RDP,\n",
    "             average_income,\n",
    "             mean_income,\n",
    "             income_class_by_housing_type,\n",
    "             minimum_housing_supply,\n",
    "             param[\"coeff_A\"],\n",
    "             income_2011)\n",
    "\n",
    "        print(\"\\n** ITERATIONS **\")\n",
    "\n",
    "        debut_iterations_time = time.process_time()\n",
    "        number_total_iterations = index_max\n",
    "\n",
    "        # Then we optimize over the number of households per housing type\n",
    "        # PER PIXEL, and not just on the aggregate number (to acccount for\n",
    "        # differing disamenities per location, e.g. eviction probability,\n",
    "        # infrastructure networks, etc.)\n",
    "\n",
    "        # To do so, we use granular housing_types (from SAL data) instead of\n",
    "        # aggregate housing_types\n",
    "\n",
    "        for index in range(0, index_max):\n",
    "\n",
    "            # IS\n",
    "            diff_is = np.zeros(24014)\n",
    "            for i in range(0, 24014):\n",
    "                diff_is[i] = (housing_types.informal_grid[i]\n",
    "                              - initial_state_households_housing_types[2, :][i]\n",
    "                              )\n",
    "                # We apply an empirical reweighting that helps convergence\n",
    "                adj = (diff_is[i] / 150000)\n",
    "                # We increase the amenity score when we underestimate the nb of\n",
    "                # HHs\n",
    "                param[\"pockets\"][i] = param[\"pockets\"][i] + adj\n",
    "            # We store iteration outcome and prevent extreme sorting from\n",
    "            # happening due to the amenity score\n",
    "            metrics_is[index] = sum(np.abs(diff_is))\n",
    "            param[\"pockets\"][param[\"pockets\"] < 0.05] = 0.05\n",
    "            param[\"pockets\"][param[\"pockets\"] > 0.99] = 0.99\n",
    "            save_param_informal_settlements[index, :] = param[\"pockets\"]\n",
    "\n",
    "            # IB\n",
    "            diff_ib = np.zeros(24014)\n",
    "            for i in range(0, 24014):\n",
    "                if options[\"actual_backyards\"] == 1:\n",
    "                    diff_ib[i] = (\n",
    "                        housing_types.backyard_informal_grid[i]\n",
    "                        + housing_types.backyard_formal_grid[i]\n",
    "                        - initial_state_households_housing_types[1, :][i])\n",
    "                elif options[\"actual_backyards\"] == 0:\n",
    "                    diff_ib[i] = (\n",
    "                        housing_types.backyard_informal_grid[i]\n",
    "                        - initial_state_households_housing_types[1, :][i])\n",
    "                adj = (diff_ib[i] / 75000)\n",
    "                param[\"backyard_pockets\"][i] = (\n",
    "                    param[\"backyard_pockets\"][i] + adj)\n",
    "            metrics_ib[index] = sum(np.abs(diff_ib))\n",
    "            param[\"backyard_pockets\"][param[\"backyard_pockets\"] < 0.05] = 0.05\n",
    "            param[\"backyard_pockets\"][param[\"backyard_pockets\"] > 0.99] = 0.99\n",
    "            save_param_backyards[index, :] = param[\"backyard_pockets\"]\n",
    "\n",
    "            metrics[index] = metrics_is[index] + metrics_ib[index]\n",
    "\n",
    "            # We run the equilibrium again with updated values of\n",
    "            # informal/backyard housing disamenity indices, then go to the next\n",
    "            # iteration\n",
    "\n",
    "            (initial_state_utility, initial_state_error,\n",
    "             initial_state_simulated_jobs,\n",
    "             initial_state_households_housing_types,\n",
    "             initial_state_household_centers,\n",
    "             initial_state_households, initial_state_dwelling_size,\n",
    "             initial_state_housing_supply, initial_state_rent,\n",
    "             initial_state_rent_matrix, initial_state_capital_land,\n",
    "             initial_state_average_income, initial_state_limit_city\n",
    "             ) = eqcmp.compute_equilibrium(\n",
    "                 fraction_capital_destroyed, amenities, param, housing_limit,\n",
    "                 population, households_per_income_class, total_RDP,\n",
    "                 coeff_land, income_net_of_commuting_costs, grid, options,\n",
    "                 agricultural_rent, interest_rate, number_properties_RDP,\n",
    "                 average_income, mean_income, income_class_by_housing_type,\n",
    "                 minimum_housing_supply, param[\"coeff_A\"], income_2011)\n",
    "\n",
    "            time_elapsed = time.process_time() - debut_iterations_time\n",
    "            iteration_number = index + 1\n",
    "\n",
    "            print(f\"iteration {iteration_number}/{number_total_iterations}\",\n",
    "                  str(datetime.timedelta(seconds=round(time_elapsed))),\n",
    "                  f\"elapsed ({round(time_elapsed/iteration_number)}s / iter)\",\n",
    "                  \"There remains:\",\n",
    "                  str(datetime.timedelta(seconds=round(\n",
    "                      time_elapsed\n",
    "                      / iteration_number\n",
    "                      * (number_total_iterations-iteration_number))))\n",
    "                  )\n",
    "\n",
    "        # We pick the set of parameters that minimize the sum of absolute diffs\n",
    "        # between data and simulation\n",
    "        score_min = np.min(metrics)\n",
    "        index_min = np.argmin(metrics)\n",
    "        # metrics[index_min]\n",
    "        param[\"pockets\"] = save_param_informal_settlements[index_min]\n",
    "        param[\"backyard_pockets\"] = save_param_backyards[index_min]\n",
    "\n",
    "        print(np.nanmin(param[\"pockets\"]))\n",
    "        print(np.nanmean(param[\"pockets\"]))\n",
    "        print(np.nanmax(param[\"pockets\"]))\n",
    "        print(np.nanmin(param[\"backyard_pockets\"]))\n",
    "        print(np.nanmean(param[\"backyard_pockets\"]))\n",
    "        print(np.nanmax(param[\"backyard_pockets\"]))\n",
    "\n",
    "        try:\n",
    "            os.mkdir(path_precalc_inp)\n",
    "        except OSError as error:\n",
    "            print(error)\n",
    "\n",
    "        np.save(path_precalc_inp + 'param_pockets.npy',\n",
    "                param[\"pockets\"])\n",
    "        np.save(path_precalc_inp + 'param_backyards.npy',\n",
    "                param[\"backyard_pockets\"])\n",
    "\n",
    "    print(\"Calibration process - end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891d5c27",
   "metadata": {
    "title": "Compute initial state"
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"Compute initial state\")\n",
    "\n",
    "# NB: Note that we use a Cobb-Douglas production function all along!\n",
    "# Also note that we simulate households as being a couple\n",
    "\n",
    "# NB: Do some bootstrapping\n",
    "\n",
    "(initial_state_utility,\n",
    " initial_state_error,\n",
    " initial_state_simulated_jobs,\n",
    " initial_state_households_housing_types,\n",
    " initial_state_household_centers,\n",
    " initial_state_households,\n",
    " initial_state_dwelling_size,\n",
    " initial_state_housing_supply,\n",
    " initial_state_rent,\n",
    " initial_state_rent_matrix,\n",
    " initial_state_capital_land,\n",
    " initial_state_average_income,\n",
    " initial_state_limit_city) = eqcmp.compute_equilibrium(\n",
    "     fraction_capital_destroyed,\n",
    "     amenities,\n",
    "     param,\n",
    "     housing_limit,\n",
    "     population,\n",
    "     households_per_income_class,\n",
    "     total_RDP,\n",
    "     coeff_land,\n",
    "     income_net_of_commuting_costs,\n",
    "     grid,\n",
    "     options,\n",
    "     agricultural_rent,\n",
    "     interest_rate,\n",
    "     number_properties_RDP,\n",
    "     average_income,\n",
    "     mean_income,\n",
    "     income_class_by_housing_type,\n",
    "     minimum_housing_supply,\n",
    "     param[\"coeff_A\"],\n",
    "     income_2011)\n",
    "\n",
    "# Reminder: income groups are ranked from poorer to richer, and housing types\n",
    "# follow the following order: formal-backyard-informal-RDP\n",
    "\n",
    "# Note on outputs (with dimensions in same order as axes):\n",
    "# initial_state_utility = utility for each income group (no RDP)\n",
    "#   after optimization\n",
    "# initial_state_error = value of error term for each group after optimization\n",
    "# initial_state_simulated_jobs = total number of households per housing type\n",
    "#   (no RDP) and income group\n",
    "# initial_state_households_housing_types = number of households\n",
    "#   per housing type (with RDP) per pixel\n",
    "# initial_state_household_centers = number of households per income group\n",
    "#   per pixel\n",
    "# initial_state_households = number of households in each housing type\n",
    "#   and income group per pixel\n",
    "# initial_state_dwelling_size = dwelling size (in m²) for each housing type\n",
    "#   per pixel\n",
    "# initial_state_housing_supply = housing surface built (in m²) per unit of\n",
    "#   available land (in km²) for each housing type in each pixel\n",
    "# initial_state_rent = average rent (in rands/m²) for each housing type\n",
    "#   in each pixel\n",
    "# initial_state_rent_matrix = average willingness to pay (in rands)\n",
    "#   for each housing type (no RDP) and each income group in each pixel\n",
    "# initial_state_capital_land = value of the (housing construction sector)\n",
    "#   capital stock (in available-land unit equivalent) per unit of available\n",
    "#   land (in km²) in each housing type (no RDP) and each selected pixel\n",
    "# initial_state_average_income = average income per income group\n",
    "#   (not an output of the model)\n",
    "# initial_state_limit_city = indicator dummy for having strictly more\n",
    "#   than one household per housing type and income group in each pixel\n",
    "\n",
    "# Save outputs\n",
    "\n",
    "try:\n",
    "    os.mkdir(path_outputs + name)\n",
    "except OSError as error:\n",
    "    print(error)\n",
    "\n",
    "\n",
    "np.save(path_outputs + name + '/initial_state_utility.npy',\n",
    "        initial_state_utility)\n",
    "np.save(path_outputs + name + '/initial_state_error.npy',\n",
    "        initial_state_error)\n",
    "np.save(path_outputs + name + '/initial_state_simulated_jobs.npy',\n",
    "        initial_state_simulated_jobs)\n",
    "np.save(path_outputs + name + '/initial_state_households_housing_types.npy',\n",
    "        initial_state_households_housing_types)\n",
    "np.save(path_outputs + name + '/initial_state_household_centers.npy',\n",
    "        initial_state_household_centers)\n",
    "np.save(path_outputs + name + '/initial_state_households.npy',\n",
    "        initial_state_households)\n",
    "np.save(path_outputs + name + '/initial_state_dwelling_size.npy',\n",
    "        initial_state_dwelling_size)\n",
    "np.save(path_outputs + name + '/initial_state_housing_supply.npy',\n",
    "        initial_state_housing_supply)\n",
    "np.save(path_outputs + name + '/initial_state_rent.npy',\n",
    "        initial_state_rent)\n",
    "np.save(path_outputs + name + '/initial_state_rent_matrix.npy',\n",
    "        initial_state_rent_matrix)\n",
    "np.save(path_outputs + name + '/initial_state_capital_land.npy',\n",
    "        initial_state_capital_land)\n",
    "np.save(path_outputs + name + '/initial_state_average_income.npy',\n",
    "        initial_state_average_income)\n",
    "np.save(path_outputs + name + '/initial_state_limit_city.npy',\n",
    "        initial_state_limit_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9439358c",
   "metadata": {
    "title": "Scenarios"
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"Compute simulations\")\n",
    "\n",
    "# RUN SIMULATION: time depends on the timeline (long with 30 years)\n",
    "(simulation_households_center,\n",
    " simulation_households_housing_type,\n",
    " simulation_dwelling_size,\n",
    " simulation_rent,\n",
    " simulation_households,\n",
    " simulation_error,\n",
    " simulation_housing_supply,\n",
    " simulation_utility,\n",
    " simulation_deriv_housing,\n",
    " simulation_T) = eqsim.run_simulation(\n",
    "     t,\n",
    "     options,\n",
    "     param,\n",
    "     grid,\n",
    "     initial_state_utility,\n",
    "     initial_state_error,\n",
    "     initial_state_households,\n",
    "     initial_state_households_housing_types,\n",
    "     initial_state_housing_supply,\n",
    "     initial_state_household_centers,\n",
    "     initial_state_average_income,\n",
    "     initial_state_rent,\n",
    "     initial_state_dwelling_size,\n",
    "     fraction_capital_destroyed,\n",
    "     amenities,\n",
    "     housing_limit,\n",
    "     spline_estimate_RDP,\n",
    "     spline_land_constraints,\n",
    "     spline_land_backyard,\n",
    "     spline_land_RDP,\n",
    "     spline_land_informal,\n",
    "     income_class_by_housing_type,\n",
    "     path_precalc_transp,\n",
    "     spline_RDP,\n",
    "     spline_agricultural_rent,\n",
    "     spline_interest_rate,\n",
    "     spline_population_income_distribution,\n",
    "     spline_inflation,\n",
    "     spline_income_distribution,\n",
    "     spline_population,\n",
    "     spline_income,\n",
    "     spline_minimum_housing_supply,\n",
    "     spline_fuel,\n",
    "     income_2011\n",
    "     )\n",
    "\n",
    "# Save outputs\n",
    "\n",
    "try:\n",
    "    os.mkdir(path_outputs + name)\n",
    "except OSError as error:\n",
    "    print(error)\n",
    "\n",
    "np.save(path_outputs + name + '/simulation_households_center.npy',\n",
    "        simulation_households_center)\n",
    "np.save(path_outputs + name + '/simulation_households_housing_type.npy',\n",
    "        simulation_households_housing_type)\n",
    "np.save(path_outputs + name + '/simulation_dwelling_size.npy',\n",
    "        simulation_dwelling_size)\n",
    "np.save(path_outputs + name + '/simulation_rent.npy',\n",
    "        simulation_rent)\n",
    "np.save(path_outputs + name + '/simulation_households.npy',\n",
    "        simulation_households)\n",
    "np.save(path_outputs + name + '/simulation_error.npy',\n",
    "        simulation_error)\n",
    "np.save(path_outputs + name + '/simulation_housing_supply.npy',\n",
    "        simulation_housing_supply)\n",
    "np.save(path_outputs + name + '/simulation_utility.npy',\n",
    "        simulation_utility)\n",
    "np.save(path_outputs + name + '/simulation_deriv_housing.npy',\n",
    "        simulation_deriv_housing)\n",
    "np.save(path_outputs + name + '/simulation_T.npy',\n",
    "        simulation_T)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
